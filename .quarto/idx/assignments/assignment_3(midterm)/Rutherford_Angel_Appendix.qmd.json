{"title":"Philadelphia Housing Model - Technical Appendix","markdown":{"yaml":{"title":"Philadelphia Housing Model - Technical Appendix","author":"Angel Rutherford","format":{"html":{"code-fold":"show","toc":true,"toc-location":"left","theme":"cosmo"}},"execute":{"warning":false,"message":false}},"headingText":"Phase 1: Data Preparation","containsRefs":false,"markdown":"\n\n\nIn this analysis, we attempt to measure what factors we can use to predict the sale prices of residential properties in Philadelphia. In order to prepare the dataset for modeling residential property sales, we applied a series of targeted cleaning and structural, socioeconomic, and spatial variable selection.\n\nWe filtered our property sales data to only show sales for the past two years to ensure up-to-date insights. We restricted the dataset to `\"SINGLE FAMILY\"` and `\"MULTI FAMILY\"` homes, excluding apartments and non-residential sales to ensure comparability, relevancy, and accuracy in our prediction models. Various apartments contained within the same building were found to be listed with a comprehensive sales price of the entire building which posed the threat of distorting our analysis. Observation values that were regarded as data entry errors or outliers were also removed. Properties with zero bathrooms, bedrooms, or livable area were removed as well as properties with a sales price below \\$10,000 and above \\$1,000,000. \n\nWe retained select structural attributes from our original dataset that we considered theoretically relevant to predicting sale price: number of bedrooms, number of bathrooms, total livable area, year the home was built, exterior condition, availability of garage spaces, and finally, the dependent variable, sale price.\n\n\n**Code for Property Sales Data Cleaning and Variable Selection**\n```{r load and clean sales data, echo=TRUE, results='hide'}\n\n#load necessary libraries\nlibrary(modelsummary)\nlibrary(stargazer)\nlibrary(sf)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(caret)\nlibrary(knitr)\nlibrary(scales)\n\n#load census key for later use\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\")\n\n#save data in url \nurl <- \"https://phl.carto.com/api/v2/sql?filename=opa_properties_public&format=geojson&skipfields=cartodb_id&q=SELECT+*+FROM+opa_properties_public\"\n\n#suppress warnings for clarity and read data as spatial object\nsuppressWarnings({\n property_data <- st_read(url)\n})\n\n#clean data\nparcel_data <- property_data%>%\n  select(location, #load columns that could potentially be used as predictors \n         category_code_description, #maybe garage_spaces and central air too?\n         number_of_bedrooms,\n         number_of_bathrooms, \n         total_livable_area,\n         year_built,\n         exterior_condition,\n         garage_spaces,\n         sale_price,\n         sale_date)%>%\n  filter(category_code_description %in% \n  c(\"SINGLE FAMILY\",\"MULTI FAMILY\"))%>% #no apartments, sales price of building\n  drop_na(number_of_bedrooms, #remove anomalies like houses with no rooms\n          number_of_bathrooms,\n          total_livable_area,\n          sale_price,\n          year_built) %>%\n  filter(number_of_bedrooms>0, \n         number_of_bathrooms>0,\n         total_livable_area>0, \n         sale_price>=10000, sale_price <=1000000)%>% #remove very low/high prices\n  mutate(sale_year = str_remove(sale_date, \"-.*\"))%>%   \n  filter(sale_year %in% c(\"2023\",\"2024\"))%>% #limit to only 2023 and 2024\n  mutate(year_built = as.numeric(year_built))%>%\n  mutate(Age = 2025 - year_built)%>% filter(Age <2000)%>% #create a age column\n  filter(exterior_condition != 0) %>% #create exterior condition binary  \n  mutate(\n    exterior_good = case_when(\n      exterior_condition >= 1 & exterior_condition <= 5 ~ 1,\n      exterior_condition >= 6 & exterior_condition <= 9 ~ 0,\n      TRUE ~ NA_real_ \n    )\n  )\n\n```\n\n```{r property data summary table, echo=FALSE}\n\n#create dataframes to put in kable\ndim_raw <- data.frame(\n  Dataset = \"Raw Property Data\",\n  Rows = nrow(property_data),\n  Columns = ncol(property_data)\n)\n\ndim_clean <- data.frame(\n  Dataset = \"Cleaned Parcel Data\",\n  Rows = nrow(parcel_data),\n  Columns = ncol(parcel_data)\n)\n\ndim_summary1 <- bind_rows(dim_raw, dim_clean)\nkable(dim_summary1, caption = \"Table 1. Property Dataset Dimensions Before and After Cleaning and Selecting Varaiables\")\n\n```\n\n\nWe derived our socioeconomic predictors from tract-level census data provided by the 2022 American Community Survey: median income, number with at least a bachelor's degree, total number of those with at least a bachelor's degree, number of those living in poverty, and total of those living in poverty. Census tracts with missing median income or zero reported as the median income were removed as it often indicated missing or zero values for other key predictors. We also mutated our census dataset to include two more columns, the percentage of people with bachelors and percentage of people in poverty, in order to standardize the observations across varying tract population sizes. Spatial data of the census tracts was also loaded in order to join our census variables to our parcel-level property data.\n\n\n**Code for Census Data Cleaning and Variable Selection**\n```{r load and clean census data, echo=TRUE, results='hide'}\n\n#load data about poverty(counts and total), bachelors(counts and total), and income \ncensus_data <- get_acs(\n  geography = \"tract\",\n  state = \"PA\",\n  county = \"Philadelphia\",\n  variables = c(\n    median_income = \"B19013_001\",\n    num_with_bach = \"B15003_022\",\n    bachelors_total =\"B15003_001\",\n    num_in_poverty = \"B17001_002\",\n    poverty_total =\"B17001_001\"\n  ),\n  year = 2022,\n  output = \"wide\"\n)\n\n#create percentage columns for bachelors and poverty \nphilly_census <- census_data%>%\n  mutate(\n    percentage_bach = num_with_bachE / bachelors_totalE,\n    percentage_pov =  num_in_povertyE / poverty_totalE\n  )\n\n#remove data errors or incomplete fields \nphilly_census <- philly_census%>%\n  drop_na(median_incomeE)%>%\n  filter(median_incomeE>0)\n\n\n#spatial census data \nphiladelphia_tracts <- tracts(\n  state = \"PA\",\n  county = \"Philadelphia\",\n  cb = TRUE,\n  year = 2022\n)\n\n#join census data and tract geometry to PARCEL data\nparcel_data <- parcel_data %>%\n  st_transform(st_crs(philadelphia_tracts))%>%\n  st_join(philadelphia_tracts, join = st_within)%>%\n  left_join(philly_census, by = \"GEOID\")\n\n```\n\n```{r census summary table, echo=FALSE}\n\n#create dataframes to put in kable\ndim_census <- data.frame(\n  Dataset = \"Census Data\",\n  Rows = nrow(census_data),\n  Columns = ncol(census_data)\n)\n\ndim_cen_clean <- data.frame(\n  Dataset = \"Cleaned Census Data\",\n  Rows = nrow(philly_census),\n  Columns = ncol(philly_census)\n)\n\ndim_summary2 <- bind_rows(dim_census, dim_cen_clean)\nkable(dim_summary2, caption = \"Table 2. Census Dataset Dimensions Before and After Cleaning and Selecting Varaiables\")\n\n```\n\n\nTo further contextualize house prices, we loaded spatial datasets including the locations of colleges and universities, 2024 crime incidents, and Philadelphia neighborhood boundaries. These datasets were loaded with the intention of engineering spatial features such as proximity measurements and neighborhood stratification in order to account for spatial patterns and potential interactive spatial effects within our predictive model. Only the 2024 crime incidents needed to be cleaned due to the missing geometries that would prevent spatial analysis.\n\n**Code for Spatial Data Cleaning and Variable Selection**\n```{r load and clean spatial data, echo=TRUE, results='hide'}\n\n#load university data\nuniversity_data <- st_read(\"./data/Universities_Colleges.geojson\")\n\n#load 2024 crime incident data\norg_crime_data <-st_read(\"./data/incidents_part1_part2.shp\")\n\n#removed crime incidents with no geometry \ncrime_data <- org_crime_data %>%\n  filter(!st_is_empty(geometry))\n\n#load neighborhood data \nneighborhoods <- st_read(\"./data/philadelphia-neighborhoods.shp\")\n\n```\n\n```{r spatial data summary table, echo=FALSE}\n\n#create dataframes to put in kable\ndim_crime <- data.frame(\n  Dataset = \"Crime Data\",\n  Rows = nrow(org_crime_data),\n  Columns = ncol(org_crime_data)\n)\n\ndim_cri_clean <- data.frame(\n  Dataset = \"Cleaned Crime Data\",\n  Rows = nrow(crime_data),\n  Columns = ncol(crime_data)\n)\n\ndim_summary3 <- bind_rows(dim_crime, dim_cri_clean)\n\nkable(dim_summary3, caption = \"Table 3. Spatial Datasets Dimensions Before and After Cleaning\")\n\n```\n\n\n# Phase 2: Exploratory Data Analysis\n\nWe created a histogram to visualize the distribution of home sale prices in Philadelphia. The resulting graph revealed a positively skewed distribution, indicating that most properties were sold at lower price points, primarily between \\$150,000 and \\$350,000, while a small number of high-value homes sold for up to \\$1,000,000. As it pertains to our predictive model, this skewness suggests that a log-transformation of sale prices may be necessary to normalize the distribution of values and potentially improve model performance. It also indicates the need for diagnostic checks to determine the impact of outliers in order to ensure that the few high-priced homes do not distort our model estimates.\n\n```{r histogram of prices, echo=FALSE}\n\n#distribution of sales prices \nggplot(parcel_data, aes(x = sale_price)) +\n  geom_histogram(binwidth = 50000, fill = \"lightblue\", color = \"darkblue\") +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(\n    title = \" Figure 1. Distribution of Home Sale Prices\",\n    x = \"Sale Price\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()+\n   theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n\n```\nWe also explored the geographic distribution of sales prices across the neighborhoods in Philadelphia. We calculated the median sales price by each Philadelphia neighborhood. The map in Figure 2 shows distinct spatial patterns with higher prices above \\$400,000, represented by lighter colors, being concentrated in neighborhoods such as Center City, University City, and parts of Northwest Philadelphia. \n\n```{r chloropleth geographic distribution, echo=FALSE}\n\n#change projection to prep for join\nparcel_proj <- st_transform(parcel_data, 3365)\nneighborhood_proj <-st_transform(neighborhoods, 3365)\n\n#associate houses with neighborhoods by joining them based on neighborhoods they fall into \nparcel_with_neighborhood <-  st_join(parcel_proj, neighborhood_proj, join = st_within)%>%\n  st_drop_geometry()%>%\n  group_by(NAME) %>%\n  summarize(median_price = median(sale_price, na.rm = TRUE)) #calculate median sales price\n\nneighborhoods_and_prices <- left_join(parcel_with_neighborhood, neighborhoods, by=\"NAME\")\nneighborhoods_and_prices <- st_as_sf(neighborhoods_and_prices)\n\n#plot chloropleth\n\n ggplot(neighborhoods_and_prices) +\n  geom_sf(aes(fill = median_price), color = \"white\", size = 0.1) +\n  scale_fill_viridis_c(option = \"plasma\", \n                       name = \"Median Sale Price\", \n                       na.value = \"grey80\",\n                        labels = scales::label_dollar()) +\n  theme_void() +\n  labs(\n    title = \"Figure 2. Median Sale Price by Philadelphia Neighborhood\"\n  )\n\n```\nOne interesting relationship we found when exploring the structural predictors of sales price was the non-linear association between home age and sale price. Because we have already determined that sale prices are not normally distributed, we plotted our predictors by the log-transformed sale price to limit distortion when attempting to assess the relationship between predictors and sales price. Even with this transformation, Figure 3 shows that sale prices tend to decline for middle-aged homes but rebound for older, more historic properties. The figure includes both a linear and quadratic line to further emphasize that a linear relationship is not sufficient in capturing the impact of age on house prices. \n\n```{r structural scatterplot, echo=FALSE}\n\n#create logged sales price for plotting \nparcel_data <- parcel_data%>%\n  mutate(log_sale_price = log(sale_price))\n\nggplot(parcel_data, aes(x = Age, y = log_sale_price)) +\n  geom_point(alpha = 0.3, color=\"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  geom_smooth(method = \"loess\", color = \"blue\", se = FALSE) +\n  labs(\n    title = \"Figure 3. House Age vs. Sale Price (logged): Linear (red) vs. Flexible Curve (blue)\",\n    x = \"Age (years)\",\n    y = \"Sale Price (%)\",\n    caption = \"Red = linear assumption, Blue = data-driven curve\"\n  ) +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n  \n\n\n```\n\nOne spatial factor that we found theoretically relevant to predicting sales price was proximity to violent crimes. We hypothesized that a home's proximity to violent crimes such as homicides, aggravated assaults with and without firearms, and armed robberies may lead to a depreciation in house value. To measure this, loaded the location of crime incidents 2024 and calculated the density of crime within 600 feet of each home. In Figure 4 we explored this relationship between violent crimes and found a general negative trend between proximity to crime and sale price. \n\n```{r spatial scatterplot, echo=FALSE}\n\n#set crs for distance calculations\ncrime_proj <- st_transform(crime_data, 3365)\nparcel_proj <- st_transform(parcel_data, 3365)\n\n#proximity (within 600 feet) to violent crime\n\nparcel_buffers<- st_buffer(parcel_proj, dist=600)\n\nviolent_crimes <- c(\"Homicide - Criminal\",\"Aggravated Assault No Firearm\",\"Robbery Firearm\",\"Aggravated Assault Firearm\")\n\nviolent_proj <- crime_proj %>%\n  filter(text_gener %in% violent_crimes)\n    \nviolent_crime_counts <- st_intersects(parcel_buffers, violent_proj)\nviolent_crime_counts <- lengths(violent_crime_counts)\nparcel_data$violent_crime_600ft <- violent_crime_counts\n\nggplot(parcel_data, aes(x = violent_crime_counts, y = log_sale_price)) +\n  geom_point(alpha = 0.3, color=\"steelblue\") +\n   geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  labs(\n    title = \"Figure 4. Counts of Violent Crimes within 600 feet vs. Sale Price\\n (logged): Linear Trend (red)\",\n    x = \"Number of Violent Crimes\",\n    y = \"Sale Price (%)\",\n     caption = \"Red = linear assumption\"\n  ) +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\" \n  )\n  \n```\nWe also created a violin plot to illustrates the distribution and density of sale prices across within the top ten neighborhoods with the highest median sale prices. The violin plot in Figure 5 reveals heterogeneity in sale prices within the wealthiest neighborhoods, indicating juxtaposition of high and low sales prices within close proximity of one another. While some neighborhoods are more concentrated at similar sales prices, neighborhoods like Bella Vista and Northern Liberties had long tails extending towards the lowest sale prices. \n\n```{r create visual (figure 5), echo=FALSE}\n\ntop_ten<- neighborhoods_and_prices%>%\n  drop_na()%>%\n  arrange(desc(median_price))%>%\n  slice_head(n=10)%>%\n  pull(NAME)\n\nhouses_in_wealth <- parcel_proj%>%\n  st_join(neighborhood_proj, by=st_within)%>%\n  filter(NAME %in% top_ten)\n\nggplot(houses_in_wealth, aes(x = NAME, y = log_sale_price)) +\n  geom_violin(fill = \"lightblue\", color = \"darkblue\", alpha = 0.6) +\n  labs(\n    title = \"Figure 5. Distribution of Sale Prices (logged) in Wealthly Philadelphia Neighborhoods\",\n    x = \"Wealthy Neighborhood\",\n    y = \"Sale Price (%)\"\n  ) +\n  theme_minimal() +\n    theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\",\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n```\n\n# Phase 3: Feature Engineering \n\nIn order to account for the spatial patterns highlight during the exploratory phase, we created a number of spatial features to incorporate into our predictive model.\n\n**Code for Feature Engineering: Crime Buffer**  \n```{r buffer crime feature engineering, echo=TRUE, results='hide'}\n\n#set crs for distance calculations\ncrime_proj <- st_transform(crime_data, 3365)\nparcel_proj <- st_transform(parcel_data, 3365)\nuniversity_proj <- st_transform(university_data, 3365)\n\n#proximity (within 600 feet) to violent crime\n\nparcel_buffers<- st_buffer(parcel_proj, dist=600)\n\nviolent_crimes <- c(\"Homicide - Criminal\",\"Aggravated Assault No Firearm\",\"Robbery Firearm\",\"Aggravated Assault Firearm\")\n\nviolent_proj <- crime_proj %>%\n  filter(text_gener %in% violent_crimes)\n    \nviolent_crime_counts <- st_intersects(parcel_buffers, violent_proj)\nviolent_crime_counts <- lengths(violent_crime_counts)\nparcel_data$violent_crime_600ft <- violent_crime_counts\n\n```\n\n**Code for Feature Engineering: K-Nearest Neighbor for Colleges**\n```{r knn college feature engineering, echo=TRUE, results='hide'}\n\n#knn to university \n\nuniversity_proj <- st_transform(university_data, 3365) #projection changed in order to calculate distance \n\n\ndist_matrix <- st_distance(parcel_proj, university_proj)\n\n\nget_knn_distance <- function(dist_matrix, k) {\n  apply(dist_matrix, 1, function(distances) {\n    mean(as.numeric(sort(distances)[1:k]))\n  })\n}\n\nparcel_data$college_nn1 <- get_knn_distance(dist_matrix, k = 1)\nparcel_data$college_nn3 <- get_knn_distance(dist_matrix, k = 3)\nparcel_data$college_nn5 <- get_knn_distance(dist_matrix, k = 5)\n\n#determine which nearest neighbor is correlated the most with sales price \n\nparcel_data %>% \n  st_drop_geometry() %>%\n  select(sale_price, college_nn1, college_nn3, college_nn5) %>%\n  cor(use = \"complete.obs\") %>%\n  as.data.frame() %>%\n  select(sale_price)\n\n```\n\n**Code for Feature Engineering: Neighborhood Interaction Effects**\n```{r neighborhood interaction effects, echo=TRUE, results='hide'}\n\n# wealthy neighborhood interaction effects\nparcel_proj <- st_transform(parcel_data, 3365)\nneighborhood_proj <-st_transform(neighborhoods, 3365)\n\n\n#median sales price \nwealthy_neighborhoods <- parcel_with_neighborhood%>%\n  filter(median_price >= 275500)%>%\n  pull(NAME)\n\n#finding the parcels that fall within neighborhood boundaries \nparcel_data <- parcel_proj %>%\n  st_join(neighborhood_proj, join = st_within) %>%\n  mutate(\n    wealthy_neighborhood = ifelse(NAME %in% wealthy_neighborhoods, \"Wealthy\", \"Not Wealthy\"), #creating a flag to delineate them into two categories \n    wealthy_neighborhood = as.factor(wealthy_neighborhood)\n  )\n\n```\n\n\n```{r summary table of spatial features, echo=FALSE}\n#Summary table of engineered features\n\n# Create a data frame summarizing each feature\nfeature_summary <- data.frame(\n  Feature_Name = c(\n    \"violent_crime_600ft\",\n    \"college_nn1\",\n    \"college_nn3\",\n    \"college_nn5\",\n    \"median_incomeE\",\n    \"percentage_bach\",\n    \"percentage_pov\",\n    \"wealthy_neighborhood\",\n    \"log_sale_price\",\n    \"log_livable_area\",\n    \"Age\",\n    \"exterior_good\"\n  ),\n  Feature_Type = c(\n    \"Buffer-based (spatial)\",\n    \"kNN (spatial distance)\",\n    \"kNN (spatial distance)\",\n    \"kNN (spatial distance)\",\n    \"Census (socioeconomic)\",\n    \"Census (education)\",\n    \"Census (poverty)\",\n    \"Interaction term (categorical)\",\n    \"Transformation (continuous)\",\n    \"Transformation (continuous)\",\n    \"Structural (numeric)\",\n    \"Condition (binary)\"\n  ),\n  Description = c(\n    \"Count of violent crimes within 600 ft of parcel\",\n    \"Average distance to nearest college/university (k=1)\",\n    \"Average distance to 3 nearest colleges/universities\",\n    \"Average distance to 5 nearest colleges/universities\",\n    \"Median household income of census tract\",\n    \"Percent of tract population with bachelor's degree\",\n    \"Percent of tract population below poverty line\",\n    \"Indicates parcels located in wealthy neighborhoods\",\n    \"Natural log of sale price\",\n    \"Natural log of total livable area (sq ft)\",\n    \"Years since building construction\",\n    \"1 = good/average exterior, 0 = poor\"\n  ),\n  Justification = c(\n    \"Captures neighborhood safety and crime exposure\",\n    \"Measures proximity to educational amenities\",\n    \"Captures local educational accessibility\",\n    \"Captures broader proximity to higher education hubs\",\n    \"Represents economic conditions of local area\",\n    \"Education level could be connected to property values\",\n    \"Reflects socioeconomic disadvantage\",\n    \"Identifies context of neighborhood wealth levels\",\n    \"Stabilizes variance for regression modeling\",\n    \"Normalizes skewed size variable for modeling\",\n    \"Accounts for devaluation of property value with time\",\n    \"Changed categorical condition to numeric to understand exterior desirability\"\n  )\n)\n\n# Print table nicely\nlibrary(knitr)\nkable(feature_summary, caption = \"Table 4. Summary of Engineered Features\", align = \"l\")\n\n\n```\n\nThe features included were engineered to capture social, economic, and environmental factors influencing housing prices. Buffer-based and nearest-neighbor measures quantify local accessibility and safety. Census data enrich parcels with socio-economic context. Interaction terms account for neighborhood-level wealth effects which helps contextualize external features of a home, for instance homes in a wealthy neighborhood are more likely to have a higher property value than those not in a wealthy neighborhood. Applying a binary indicator improves model interpretability and performance.\n\n\n# Phase 4: Model Building\n\nWhen building our model's be progressively built out models to expand upon the last with out first model being the baseline of all our models and using only structural variables, the second model adding socioeconomic census variables, our third model introducing our spatial features, and our fourth model added spatial interactions and fixed effects. \n\n\n**Code for Model Building**\n```{r model building, echo=TRUE, results='hide'}\n\n#create log livable area for modeling\n\nparcel_data <- parcel_data%>%\n  mutate(log_livable_area = log(total_livable_area))\n\n#structural features only \nmodel1 <- lm(log_sale_price ~ number_of_bathrooms + number_of_bedrooms + log_livable_area + garage_spaces + Age + I(Age^2) + exterior_good, data = parcel_data)\n\n\n#structural + census \nmodel2 <- lm(log_sale_price ~ number_of_bathrooms + number_of_bedrooms + log_livable_area  + garage_spaces + Age + I(Age^2) + exterior_good + median_incomeE + percentage_bach + percentage_pov, data = parcel_data)\n\n#structural + census + spatial \nmodel3 <- lm(log_sale_price ~ number_of_bathrooms+ garage_spaces + Age + I(Age^2) + exterior_good + log_livable_area + median_incomeE +percentage_bach + percentage_pov + college_nn1 + violent_crime_600ft, data = parcel_data)\n\n\n#structural + census + spatial + interactions \nmodel4 <- lm(log_sale_price ~ number_of_bathrooms+ garage_spaces + Age + I(Age^2) + exterior_good + log_livable_area * wealthy_neighborhood + median_incomeE +percentage_bach + percentage_pov + college_nn1 + violent_crime_600ft, data = parcel_data)\n\n```\n\nOur summary table of coefficients for predictors by model indicate statistical numerically as well as with stars to account for low values omitted through the rounding of coefficients. \n\n**Full Model Summary of Models**\n```{r full stargazer/ model summary (table 5), echo=FALSE}\n\nmodelsummary(\n  list(\"Model 1\" = model1, \"Model 2\" = model2, \"Model 3\" = model3, \"Model 4\" = model4),\n  statistic = \"conf.int\",         # shows confidence intervals\n  stars = TRUE,                   # adds significance stars\n  output = \"markdown\",            # clean for R Markdown or console\n  gof_omit = \"AIC|BIC|Log.Lik.\" # optional: hide less relevant stats\n  )\n\n```\nAcross all models, the coefficient for the structural predictors like the number of bathrooms, garage spaces, livable area, and exterior conditions remains consistently positive and statistically significant, with livable area and exterior conditions being the most influential of the predictors. The coefficients for age and it's quadratic adjustment showed that older homes sold for less while the coefficients for the number of bedrooms showed that it became less statistically significant as non-structural predictors were introduced. \n\nAs census variables are introduced in Model 2, median income, educational attainment, and poverty rate all show expected relationships: higher income and education levels are associated with higher sale prices, while higher poverty rates are negatively associated.Our spatial features introduced in Model 3, distance from the nearest college and density of crime were also identified as statistically significant. In Model 4, the coefficient for wealthy neighborhood is large and positive. There is, however, a slight negative interaction between log(livable area) and wealthy neighborhoods. This suggests that while larger homes still tend to sell for more, the appreciation of value of each additional square foot is less pronounced in already expensive areas.\n\nOverall, the progression from Model 1 to Model 4 shows increasing explanatory power (R² rising from 0.35 to 0.60), and decreasing RMSE, indicating improved model fit as more structural and contextual variables are added.\n\n\n# Phase 5: Model Validation\n\nIn order to further assess the predictive power of our models, we performed 10-fold cross validation for each model in order to determine how well the model predicts for unseen data.\n\n**Code for 10-fold Cross-Validation**\n```{r 10 fold cross-validation results and scatterplots, echo=TRUE,results='hide'}\n\nparcel_data <- na.omit(parcel_data)\n\nctrl <- trainControl(\n  method = \"cv\",\n  number = 10  # intiate 10-fold CV\n)\n\nmodel_cv1 <-  train(log_sale_price ~ \n                      number_of_bathrooms +\n                      number_of_bedrooms +\n                      log_livable_area +\n                      garage_spaces + \n                      Age + I(Age^2) + \n                      exterior_good,\n                     data = parcel_data,\n                       method = \"lm\",\n                       trControl = ctrl)\n\n  \nmodel_cv2 <- train(log_sale_price ~ \n                     number_of_bathrooms +\n                     number_of_bedrooms + \n                     log_livable_area  +\n                     garage_spaces +\n                     Age + I(Age^2) + \n                     exterior_good + \n                     median_incomeE + \n                     percentage_bach + \n                     percentage_pov,\n                     data = parcel_data,\n                      method = \"lm\",\n                      trControl = ctrl\n)\n\n\nmodel_cv3 <- train(log_sale_price ~ \n                     number_of_bathrooms +\n                     garage_spaces +\n                     Age + I(Age^2) + \n                     exterior_good + \n                     log_livable_area +\n                     median_incomeE + \n                     percentage_bach +\n                     percentage_pov + \n                     college_nn1 + \n                     violent_crime_600ft,\n                     data = parcel_data,\n                    method = \"lm\",\n                    trControl = ctrl\n)\n\n\n\nmodel_cv4 <- train(log_sale_price ~ \n                     number_of_bathrooms+\n                     garage_spaces + \n                     Age + I(Age^2) +\n                     exterior_good + \n                     log_livable_area * wealthy_neighborhood + \n                     median_incomeE +\n                     percentage_bach + \n                     percentage_pov +\n                     college_nn1 + \n                     violent_crime_600ft,\n                     data = parcel_data,\n                      method = \"lm\",\n                    trControl = ctrl\n)\n\n```\n\n\nBased on each model's measurement average squared prediction error (RMSE),  average absolute difference between predicted and actual values (MAE), and  reported proportion of explained variance (R^2), we determined that Model 4's inclusion of structural, socioeconomic, spatial, and interactive effects all contributed to smaller errors between predicted values and actual values and offered greater explanatory power. \n\n\n```{r cross-validation summary table, echo=FALSE}\n\nresults_table <- rbind(\n  cbind(Model = \"Model 1\", model_cv1$results),\n  cbind(Model = \"Model 2\", model_cv2$results),\n  cbind(Model = \"Model 3\", model_cv3$results),\n  cbind(Model = \"Model 4\", model_cv4$results)\n)\n\nresults_table %>%\n  select(Model, RMSE, Rsquared, MAE) %>%\n  mutate(across(where(is.numeric), round, 4)) %>%\n  kable(caption = \"Table 6. Cross-Validated Performance Metrics for Four Models\")\n\n```\n\n\n\n```{r predicted vs actual plot, echo=FALSE}\n\nmodel_data_used <- model.frame(model4)\n\nmodel_data_used$Predicted <- model4$fitted.values\n\nggplot(model_data_used, aes(x = log_sale_price, y = Predicted)) +\n  geom_point(alpha = 0.4, color = \"steelblue\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Figure 6. Predicted vs Actual (Model 4)\",\n    x = \"Actual log(sale_price)\",\n    y = \"Predicted log(sale_price)\"\n  ) +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n\n```\n\nThe graph of the actual logged sale prices by the predicted logged sale prices compliments our model performance metrics found in Table 6 as points cluster closely around the reference line suggesting stable consistency in errors and moderate ability to predict sale prices.\n\n\n# Phase 6: Model Diagnostics\n\nWhen using linear regression to model relationships, we assume a number of conditions are met to support the validity of using a linear model. Here we test various linear modeling assumptions to determine the appropriateness of our model.\n\nOne linear model assumption is the assumption that the relationship is actually linear. \nIf the linearity assumption is met, residuals should be randomly scattered around the zero line with no discernible pattern.\n\nIn Figure 7, we plotted the residuals or prediction errors by the model's fitted values. The red dashed line at zero marks where residuals would fall if predictions were perfect.\nIn this plot, the residuals appear to fan out as fitted values increase, suggesting a possible violation of the linearity. This pattern may indicate that the model under- or over-predicts at different price levels.\n\n```{r residual plot, echo=FALSE}\n\nres_df <- data.frame(\n  Fitted = fitted(model4),\n  Residuals = residuals(model4)\n)\n\n# Plot using ggplot\nggplot(res_df, aes(x = Fitted, y = Residuals)) +\n  geom_point(alpha = 0.6, color=\"steelblue\") +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Figure 7. Residual Plot\", x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n  \n```\n\nAnother assumption we test is the normal distribution of residuals or errors.  In Figure 8, we test the assumption of normally distributed residuals using a Q-Q plot. If normality of residual's is met, the sample quantile points should fall roughly along the blue reference line representing theoretical quantiles of normal distribution.\n\nIn this plot, the residuals deviate from the line, particularly in the tails at low and high values, indicating non-normality. \n\n```{r q-q plot, echo=FALSE}\n\nggplot(res_df, aes(sample = Residuals)) +\n  stat_qq() +\n  stat_qq_line(color = \"steelblue\") +\n  labs(title = \"Figure 8. Q-Q Plot of Residuals\",\n       x = \"Theoretical Quantiles\",\n       y = \"Sample Quantiles\") +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n\n```\n\nOne last regression assumption check we performed was determining whether there were influential outliers present. Figure 9 displays Cook’s Distance values for each observation, with colors indicating whether the point is flagged as influential, blue being none influential observations and red being the influential obeservations. A substantial large number of our observations were marked as influential, suggesting that many data points have both high leverage and large residuals.  \n\n```{r cooks distance, echo=FALSE}\n\nmodel4_data <- model.frame(model4)\n\n# Add diagnostics to model_data\nmodel4_data <- model4_data %>%\n  mutate(\n    cooks_d = cooks.distance(model4),\n    leverage = hatvalues(model4),\n    is_influential = cooks_d > 4 / nrow(model4_data)\n  )\n\n# Plot Cook's Distance\nggplot(model4_data, aes(x = 1:nrow(model4_data), y = cooks_d)) +\n  geom_point(aes(color = is_influential), size = 2) +\n  geom_hline(yintercept = 4 / nrow(model4_data), \n             linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = c(\"steelblue\", \"red\")) +\n  labs(title = \"Figure 9. Cook's Distance\",\n       x = \"Observation\", y = \"Cook's D\") +\n  theme_minimal() +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\")\n  \n```\n\n# Phase 7: Conclusions & Recommendations\n\nThe final model demonstrates strong performance, achieving an adjusted R² of 0.591 and explaining nearly 59% of the variation in housing prices across Philadelphia. This marks a substantial improvement over the baseline structural model (Model 1, R² = 0.35), highlighting the value of incorporating  spatial characteristics alongside structural and socioeconomic factors. \n\nAmong all predictors, total livable area emerges as the most influential driver of price, followed by the number of bathrooms and garage spaces. Exterior condition, median income, and educational attainment also show positive associations. Conversely, poverty rate and local crime density are negatively associated with price. \n\nThe interaction between living area and wealthy neighborhoods reveal that additional square footage may not have as much of an impact on price in high-value areas. Spatial dependencies are also evident in the model’s predictive accuracy as prediction errors show spatial patterns. The model performs best in mid-range price neighborhoods but struggles in areas like Nicetown, Fairhill, and Upper Kensington, where residual errors are higher. These disparities raise important equity concerns in the context of policy as these areas that are predisposed to under-prediction in modeling are also historical disadvantaged neighborhoods.\n\n","srcMarkdownNoYaml":"\n\n# Phase 1: Data Preparation \n\nIn this analysis, we attempt to measure what factors we can use to predict the sale prices of residential properties in Philadelphia. In order to prepare the dataset for modeling residential property sales, we applied a series of targeted cleaning and structural, socioeconomic, and spatial variable selection.\n\nWe filtered our property sales data to only show sales for the past two years to ensure up-to-date insights. We restricted the dataset to `\"SINGLE FAMILY\"` and `\"MULTI FAMILY\"` homes, excluding apartments and non-residential sales to ensure comparability, relevancy, and accuracy in our prediction models. Various apartments contained within the same building were found to be listed with a comprehensive sales price of the entire building which posed the threat of distorting our analysis. Observation values that were regarded as data entry errors or outliers were also removed. Properties with zero bathrooms, bedrooms, or livable area were removed as well as properties with a sales price below \\$10,000 and above \\$1,000,000. \n\nWe retained select structural attributes from our original dataset that we considered theoretically relevant to predicting sale price: number of bedrooms, number of bathrooms, total livable area, year the home was built, exterior condition, availability of garage spaces, and finally, the dependent variable, sale price.\n\n\n**Code for Property Sales Data Cleaning and Variable Selection**\n```{r load and clean sales data, echo=TRUE, results='hide'}\n\n#load necessary libraries\nlibrary(modelsummary)\nlibrary(stargazer)\nlibrary(sf)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(caret)\nlibrary(knitr)\nlibrary(scales)\n\n#load census key for later use\ncensus_api_key(\"42bf8a20a3df1def380f330cf7edad0dd5842ce6\")\n\n#save data in url \nurl <- \"https://phl.carto.com/api/v2/sql?filename=opa_properties_public&format=geojson&skipfields=cartodb_id&q=SELECT+*+FROM+opa_properties_public\"\n\n#suppress warnings for clarity and read data as spatial object\nsuppressWarnings({\n property_data <- st_read(url)\n})\n\n#clean data\nparcel_data <- property_data%>%\n  select(location, #load columns that could potentially be used as predictors \n         category_code_description, #maybe garage_spaces and central air too?\n         number_of_bedrooms,\n         number_of_bathrooms, \n         total_livable_area,\n         year_built,\n         exterior_condition,\n         garage_spaces,\n         sale_price,\n         sale_date)%>%\n  filter(category_code_description %in% \n  c(\"SINGLE FAMILY\",\"MULTI FAMILY\"))%>% #no apartments, sales price of building\n  drop_na(number_of_bedrooms, #remove anomalies like houses with no rooms\n          number_of_bathrooms,\n          total_livable_area,\n          sale_price,\n          year_built) %>%\n  filter(number_of_bedrooms>0, \n         number_of_bathrooms>0,\n         total_livable_area>0, \n         sale_price>=10000, sale_price <=1000000)%>% #remove very low/high prices\n  mutate(sale_year = str_remove(sale_date, \"-.*\"))%>%   \n  filter(sale_year %in% c(\"2023\",\"2024\"))%>% #limit to only 2023 and 2024\n  mutate(year_built = as.numeric(year_built))%>%\n  mutate(Age = 2025 - year_built)%>% filter(Age <2000)%>% #create a age column\n  filter(exterior_condition != 0) %>% #create exterior condition binary  \n  mutate(\n    exterior_good = case_when(\n      exterior_condition >= 1 & exterior_condition <= 5 ~ 1,\n      exterior_condition >= 6 & exterior_condition <= 9 ~ 0,\n      TRUE ~ NA_real_ \n    )\n  )\n\n```\n\n```{r property data summary table, echo=FALSE}\n\n#create dataframes to put in kable\ndim_raw <- data.frame(\n  Dataset = \"Raw Property Data\",\n  Rows = nrow(property_data),\n  Columns = ncol(property_data)\n)\n\ndim_clean <- data.frame(\n  Dataset = \"Cleaned Parcel Data\",\n  Rows = nrow(parcel_data),\n  Columns = ncol(parcel_data)\n)\n\ndim_summary1 <- bind_rows(dim_raw, dim_clean)\nkable(dim_summary1, caption = \"Table 1. Property Dataset Dimensions Before and After Cleaning and Selecting Varaiables\")\n\n```\n\n\nWe derived our socioeconomic predictors from tract-level census data provided by the 2022 American Community Survey: median income, number with at least a bachelor's degree, total number of those with at least a bachelor's degree, number of those living in poverty, and total of those living in poverty. Census tracts with missing median income or zero reported as the median income were removed as it often indicated missing or zero values for other key predictors. We also mutated our census dataset to include two more columns, the percentage of people with bachelors and percentage of people in poverty, in order to standardize the observations across varying tract population sizes. Spatial data of the census tracts was also loaded in order to join our census variables to our parcel-level property data.\n\n\n**Code for Census Data Cleaning and Variable Selection**\n```{r load and clean census data, echo=TRUE, results='hide'}\n\n#load data about poverty(counts and total), bachelors(counts and total), and income \ncensus_data <- get_acs(\n  geography = \"tract\",\n  state = \"PA\",\n  county = \"Philadelphia\",\n  variables = c(\n    median_income = \"B19013_001\",\n    num_with_bach = \"B15003_022\",\n    bachelors_total =\"B15003_001\",\n    num_in_poverty = \"B17001_002\",\n    poverty_total =\"B17001_001\"\n  ),\n  year = 2022,\n  output = \"wide\"\n)\n\n#create percentage columns for bachelors and poverty \nphilly_census <- census_data%>%\n  mutate(\n    percentage_bach = num_with_bachE / bachelors_totalE,\n    percentage_pov =  num_in_povertyE / poverty_totalE\n  )\n\n#remove data errors or incomplete fields \nphilly_census <- philly_census%>%\n  drop_na(median_incomeE)%>%\n  filter(median_incomeE>0)\n\n\n#spatial census data \nphiladelphia_tracts <- tracts(\n  state = \"PA\",\n  county = \"Philadelphia\",\n  cb = TRUE,\n  year = 2022\n)\n\n#join census data and tract geometry to PARCEL data\nparcel_data <- parcel_data %>%\n  st_transform(st_crs(philadelphia_tracts))%>%\n  st_join(philadelphia_tracts, join = st_within)%>%\n  left_join(philly_census, by = \"GEOID\")\n\n```\n\n```{r census summary table, echo=FALSE}\n\n#create dataframes to put in kable\ndim_census <- data.frame(\n  Dataset = \"Census Data\",\n  Rows = nrow(census_data),\n  Columns = ncol(census_data)\n)\n\ndim_cen_clean <- data.frame(\n  Dataset = \"Cleaned Census Data\",\n  Rows = nrow(philly_census),\n  Columns = ncol(philly_census)\n)\n\ndim_summary2 <- bind_rows(dim_census, dim_cen_clean)\nkable(dim_summary2, caption = \"Table 2. Census Dataset Dimensions Before and After Cleaning and Selecting Varaiables\")\n\n```\n\n\nTo further contextualize house prices, we loaded spatial datasets including the locations of colleges and universities, 2024 crime incidents, and Philadelphia neighborhood boundaries. These datasets were loaded with the intention of engineering spatial features such as proximity measurements and neighborhood stratification in order to account for spatial patterns and potential interactive spatial effects within our predictive model. Only the 2024 crime incidents needed to be cleaned due to the missing geometries that would prevent spatial analysis.\n\n**Code for Spatial Data Cleaning and Variable Selection**\n```{r load and clean spatial data, echo=TRUE, results='hide'}\n\n#load university data\nuniversity_data <- st_read(\"./data/Universities_Colleges.geojson\")\n\n#load 2024 crime incident data\norg_crime_data <-st_read(\"./data/incidents_part1_part2.shp\")\n\n#removed crime incidents with no geometry \ncrime_data <- org_crime_data %>%\n  filter(!st_is_empty(geometry))\n\n#load neighborhood data \nneighborhoods <- st_read(\"./data/philadelphia-neighborhoods.shp\")\n\n```\n\n```{r spatial data summary table, echo=FALSE}\n\n#create dataframes to put in kable\ndim_crime <- data.frame(\n  Dataset = \"Crime Data\",\n  Rows = nrow(org_crime_data),\n  Columns = ncol(org_crime_data)\n)\n\ndim_cri_clean <- data.frame(\n  Dataset = \"Cleaned Crime Data\",\n  Rows = nrow(crime_data),\n  Columns = ncol(crime_data)\n)\n\ndim_summary3 <- bind_rows(dim_crime, dim_cri_clean)\n\nkable(dim_summary3, caption = \"Table 3. Spatial Datasets Dimensions Before and After Cleaning\")\n\n```\n\n\n# Phase 2: Exploratory Data Analysis\n\nWe created a histogram to visualize the distribution of home sale prices in Philadelphia. The resulting graph revealed a positively skewed distribution, indicating that most properties were sold at lower price points, primarily between \\$150,000 and \\$350,000, while a small number of high-value homes sold for up to \\$1,000,000. As it pertains to our predictive model, this skewness suggests that a log-transformation of sale prices may be necessary to normalize the distribution of values and potentially improve model performance. It also indicates the need for diagnostic checks to determine the impact of outliers in order to ensure that the few high-priced homes do not distort our model estimates.\n\n```{r histogram of prices, echo=FALSE}\n\n#distribution of sales prices \nggplot(parcel_data, aes(x = sale_price)) +\n  geom_histogram(binwidth = 50000, fill = \"lightblue\", color = \"darkblue\") +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(\n    title = \" Figure 1. Distribution of Home Sale Prices\",\n    x = \"Sale Price\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()+\n   theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n\n```\nWe also explored the geographic distribution of sales prices across the neighborhoods in Philadelphia. We calculated the median sales price by each Philadelphia neighborhood. The map in Figure 2 shows distinct spatial patterns with higher prices above \\$400,000, represented by lighter colors, being concentrated in neighborhoods such as Center City, University City, and parts of Northwest Philadelphia. \n\n```{r chloropleth geographic distribution, echo=FALSE}\n\n#change projection to prep for join\nparcel_proj <- st_transform(parcel_data, 3365)\nneighborhood_proj <-st_transform(neighborhoods, 3365)\n\n#associate houses with neighborhoods by joining them based on neighborhoods they fall into \nparcel_with_neighborhood <-  st_join(parcel_proj, neighborhood_proj, join = st_within)%>%\n  st_drop_geometry()%>%\n  group_by(NAME) %>%\n  summarize(median_price = median(sale_price, na.rm = TRUE)) #calculate median sales price\n\nneighborhoods_and_prices <- left_join(parcel_with_neighborhood, neighborhoods, by=\"NAME\")\nneighborhoods_and_prices <- st_as_sf(neighborhoods_and_prices)\n\n#plot chloropleth\n\n ggplot(neighborhoods_and_prices) +\n  geom_sf(aes(fill = median_price), color = \"white\", size = 0.1) +\n  scale_fill_viridis_c(option = \"plasma\", \n                       name = \"Median Sale Price\", \n                       na.value = \"grey80\",\n                        labels = scales::label_dollar()) +\n  theme_void() +\n  labs(\n    title = \"Figure 2. Median Sale Price by Philadelphia Neighborhood\"\n  )\n\n```\nOne interesting relationship we found when exploring the structural predictors of sales price was the non-linear association between home age and sale price. Because we have already determined that sale prices are not normally distributed, we plotted our predictors by the log-transformed sale price to limit distortion when attempting to assess the relationship between predictors and sales price. Even with this transformation, Figure 3 shows that sale prices tend to decline for middle-aged homes but rebound for older, more historic properties. The figure includes both a linear and quadratic line to further emphasize that a linear relationship is not sufficient in capturing the impact of age on house prices. \n\n```{r structural scatterplot, echo=FALSE}\n\n#create logged sales price for plotting \nparcel_data <- parcel_data%>%\n  mutate(log_sale_price = log(sale_price))\n\nggplot(parcel_data, aes(x = Age, y = log_sale_price)) +\n  geom_point(alpha = 0.3, color=\"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  geom_smooth(method = \"loess\", color = \"blue\", se = FALSE) +\n  labs(\n    title = \"Figure 3. House Age vs. Sale Price (logged): Linear (red) vs. Flexible Curve (blue)\",\n    x = \"Age (years)\",\n    y = \"Sale Price (%)\",\n    caption = \"Red = linear assumption, Blue = data-driven curve\"\n  ) +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n  \n\n\n```\n\nOne spatial factor that we found theoretically relevant to predicting sales price was proximity to violent crimes. We hypothesized that a home's proximity to violent crimes such as homicides, aggravated assaults with and without firearms, and armed robberies may lead to a depreciation in house value. To measure this, loaded the location of crime incidents 2024 and calculated the density of crime within 600 feet of each home. In Figure 4 we explored this relationship between violent crimes and found a general negative trend between proximity to crime and sale price. \n\n```{r spatial scatterplot, echo=FALSE}\n\n#set crs for distance calculations\ncrime_proj <- st_transform(crime_data, 3365)\nparcel_proj <- st_transform(parcel_data, 3365)\n\n#proximity (within 600 feet) to violent crime\n\nparcel_buffers<- st_buffer(parcel_proj, dist=600)\n\nviolent_crimes <- c(\"Homicide - Criminal\",\"Aggravated Assault No Firearm\",\"Robbery Firearm\",\"Aggravated Assault Firearm\")\n\nviolent_proj <- crime_proj %>%\n  filter(text_gener %in% violent_crimes)\n    \nviolent_crime_counts <- st_intersects(parcel_buffers, violent_proj)\nviolent_crime_counts <- lengths(violent_crime_counts)\nparcel_data$violent_crime_600ft <- violent_crime_counts\n\nggplot(parcel_data, aes(x = violent_crime_counts, y = log_sale_price)) +\n  geom_point(alpha = 0.3, color=\"steelblue\") +\n   geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  labs(\n    title = \"Figure 4. Counts of Violent Crimes within 600 feet vs. Sale Price\\n (logged): Linear Trend (red)\",\n    x = \"Number of Violent Crimes\",\n    y = \"Sale Price (%)\",\n     caption = \"Red = linear assumption\"\n  ) +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\" \n  )\n  \n```\nWe also created a violin plot to illustrates the distribution and density of sale prices across within the top ten neighborhoods with the highest median sale prices. The violin plot in Figure 5 reveals heterogeneity in sale prices within the wealthiest neighborhoods, indicating juxtaposition of high and low sales prices within close proximity of one another. While some neighborhoods are more concentrated at similar sales prices, neighborhoods like Bella Vista and Northern Liberties had long tails extending towards the lowest sale prices. \n\n```{r create visual (figure 5), echo=FALSE}\n\ntop_ten<- neighborhoods_and_prices%>%\n  drop_na()%>%\n  arrange(desc(median_price))%>%\n  slice_head(n=10)%>%\n  pull(NAME)\n\nhouses_in_wealth <- parcel_proj%>%\n  st_join(neighborhood_proj, by=st_within)%>%\n  filter(NAME %in% top_ten)\n\nggplot(houses_in_wealth, aes(x = NAME, y = log_sale_price)) +\n  geom_violin(fill = \"lightblue\", color = \"darkblue\", alpha = 0.6) +\n  labs(\n    title = \"Figure 5. Distribution of Sale Prices (logged) in Wealthly Philadelphia Neighborhoods\",\n    x = \"Wealthy Neighborhood\",\n    y = \"Sale Price (%)\"\n  ) +\n  theme_minimal() +\n    theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\",\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n```\n\n# Phase 3: Feature Engineering \n\nIn order to account for the spatial patterns highlight during the exploratory phase, we created a number of spatial features to incorporate into our predictive model.\n\n**Code for Feature Engineering: Crime Buffer**  \n```{r buffer crime feature engineering, echo=TRUE, results='hide'}\n\n#set crs for distance calculations\ncrime_proj <- st_transform(crime_data, 3365)\nparcel_proj <- st_transform(parcel_data, 3365)\nuniversity_proj <- st_transform(university_data, 3365)\n\n#proximity (within 600 feet) to violent crime\n\nparcel_buffers<- st_buffer(parcel_proj, dist=600)\n\nviolent_crimes <- c(\"Homicide - Criminal\",\"Aggravated Assault No Firearm\",\"Robbery Firearm\",\"Aggravated Assault Firearm\")\n\nviolent_proj <- crime_proj %>%\n  filter(text_gener %in% violent_crimes)\n    \nviolent_crime_counts <- st_intersects(parcel_buffers, violent_proj)\nviolent_crime_counts <- lengths(violent_crime_counts)\nparcel_data$violent_crime_600ft <- violent_crime_counts\n\n```\n\n**Code for Feature Engineering: K-Nearest Neighbor for Colleges**\n```{r knn college feature engineering, echo=TRUE, results='hide'}\n\n#knn to university \n\nuniversity_proj <- st_transform(university_data, 3365) #projection changed in order to calculate distance \n\n\ndist_matrix <- st_distance(parcel_proj, university_proj)\n\n\nget_knn_distance <- function(dist_matrix, k) {\n  apply(dist_matrix, 1, function(distances) {\n    mean(as.numeric(sort(distances)[1:k]))\n  })\n}\n\nparcel_data$college_nn1 <- get_knn_distance(dist_matrix, k = 1)\nparcel_data$college_nn3 <- get_knn_distance(dist_matrix, k = 3)\nparcel_data$college_nn5 <- get_knn_distance(dist_matrix, k = 5)\n\n#determine which nearest neighbor is correlated the most with sales price \n\nparcel_data %>% \n  st_drop_geometry() %>%\n  select(sale_price, college_nn1, college_nn3, college_nn5) %>%\n  cor(use = \"complete.obs\") %>%\n  as.data.frame() %>%\n  select(sale_price)\n\n```\n\n**Code for Feature Engineering: Neighborhood Interaction Effects**\n```{r neighborhood interaction effects, echo=TRUE, results='hide'}\n\n# wealthy neighborhood interaction effects\nparcel_proj <- st_transform(parcel_data, 3365)\nneighborhood_proj <-st_transform(neighborhoods, 3365)\n\n\n#median sales price \nwealthy_neighborhoods <- parcel_with_neighborhood%>%\n  filter(median_price >= 275500)%>%\n  pull(NAME)\n\n#finding the parcels that fall within neighborhood boundaries \nparcel_data <- parcel_proj %>%\n  st_join(neighborhood_proj, join = st_within) %>%\n  mutate(\n    wealthy_neighborhood = ifelse(NAME %in% wealthy_neighborhoods, \"Wealthy\", \"Not Wealthy\"), #creating a flag to delineate them into two categories \n    wealthy_neighborhood = as.factor(wealthy_neighborhood)\n  )\n\n```\n\n\n```{r summary table of spatial features, echo=FALSE}\n#Summary table of engineered features\n\n# Create a data frame summarizing each feature\nfeature_summary <- data.frame(\n  Feature_Name = c(\n    \"violent_crime_600ft\",\n    \"college_nn1\",\n    \"college_nn3\",\n    \"college_nn5\",\n    \"median_incomeE\",\n    \"percentage_bach\",\n    \"percentage_pov\",\n    \"wealthy_neighborhood\",\n    \"log_sale_price\",\n    \"log_livable_area\",\n    \"Age\",\n    \"exterior_good\"\n  ),\n  Feature_Type = c(\n    \"Buffer-based (spatial)\",\n    \"kNN (spatial distance)\",\n    \"kNN (spatial distance)\",\n    \"kNN (spatial distance)\",\n    \"Census (socioeconomic)\",\n    \"Census (education)\",\n    \"Census (poverty)\",\n    \"Interaction term (categorical)\",\n    \"Transformation (continuous)\",\n    \"Transformation (continuous)\",\n    \"Structural (numeric)\",\n    \"Condition (binary)\"\n  ),\n  Description = c(\n    \"Count of violent crimes within 600 ft of parcel\",\n    \"Average distance to nearest college/university (k=1)\",\n    \"Average distance to 3 nearest colleges/universities\",\n    \"Average distance to 5 nearest colleges/universities\",\n    \"Median household income of census tract\",\n    \"Percent of tract population with bachelor's degree\",\n    \"Percent of tract population below poverty line\",\n    \"Indicates parcels located in wealthy neighborhoods\",\n    \"Natural log of sale price\",\n    \"Natural log of total livable area (sq ft)\",\n    \"Years since building construction\",\n    \"1 = good/average exterior, 0 = poor\"\n  ),\n  Justification = c(\n    \"Captures neighborhood safety and crime exposure\",\n    \"Measures proximity to educational amenities\",\n    \"Captures local educational accessibility\",\n    \"Captures broader proximity to higher education hubs\",\n    \"Represents economic conditions of local area\",\n    \"Education level could be connected to property values\",\n    \"Reflects socioeconomic disadvantage\",\n    \"Identifies context of neighborhood wealth levels\",\n    \"Stabilizes variance for regression modeling\",\n    \"Normalizes skewed size variable for modeling\",\n    \"Accounts for devaluation of property value with time\",\n    \"Changed categorical condition to numeric to understand exterior desirability\"\n  )\n)\n\n# Print table nicely\nlibrary(knitr)\nkable(feature_summary, caption = \"Table 4. Summary of Engineered Features\", align = \"l\")\n\n\n```\n\nThe features included were engineered to capture social, economic, and environmental factors influencing housing prices. Buffer-based and nearest-neighbor measures quantify local accessibility and safety. Census data enrich parcels with socio-economic context. Interaction terms account for neighborhood-level wealth effects which helps contextualize external features of a home, for instance homes in a wealthy neighborhood are more likely to have a higher property value than those not in a wealthy neighborhood. Applying a binary indicator improves model interpretability and performance.\n\n\n# Phase 4: Model Building\n\nWhen building our model's be progressively built out models to expand upon the last with out first model being the baseline of all our models and using only structural variables, the second model adding socioeconomic census variables, our third model introducing our spatial features, and our fourth model added spatial interactions and fixed effects. \n\n\n**Code for Model Building**\n```{r model building, echo=TRUE, results='hide'}\n\n#create log livable area for modeling\n\nparcel_data <- parcel_data%>%\n  mutate(log_livable_area = log(total_livable_area))\n\n#structural features only \nmodel1 <- lm(log_sale_price ~ number_of_bathrooms + number_of_bedrooms + log_livable_area + garage_spaces + Age + I(Age^2) + exterior_good, data = parcel_data)\n\n\n#structural + census \nmodel2 <- lm(log_sale_price ~ number_of_bathrooms + number_of_bedrooms + log_livable_area  + garage_spaces + Age + I(Age^2) + exterior_good + median_incomeE + percentage_bach + percentage_pov, data = parcel_data)\n\n#structural + census + spatial \nmodel3 <- lm(log_sale_price ~ number_of_bathrooms+ garage_spaces + Age + I(Age^2) + exterior_good + log_livable_area + median_incomeE +percentage_bach + percentage_pov + college_nn1 + violent_crime_600ft, data = parcel_data)\n\n\n#structural + census + spatial + interactions \nmodel4 <- lm(log_sale_price ~ number_of_bathrooms+ garage_spaces + Age + I(Age^2) + exterior_good + log_livable_area * wealthy_neighborhood + median_incomeE +percentage_bach + percentage_pov + college_nn1 + violent_crime_600ft, data = parcel_data)\n\n```\n\nOur summary table of coefficients for predictors by model indicate statistical numerically as well as with stars to account for low values omitted through the rounding of coefficients. \n\n**Full Model Summary of Models**\n```{r full stargazer/ model summary (table 5), echo=FALSE}\n\nmodelsummary(\n  list(\"Model 1\" = model1, \"Model 2\" = model2, \"Model 3\" = model3, \"Model 4\" = model4),\n  statistic = \"conf.int\",         # shows confidence intervals\n  stars = TRUE,                   # adds significance stars\n  output = \"markdown\",            # clean for R Markdown or console\n  gof_omit = \"AIC|BIC|Log.Lik.\" # optional: hide less relevant stats\n  )\n\n```\nAcross all models, the coefficient for the structural predictors like the number of bathrooms, garage spaces, livable area, and exterior conditions remains consistently positive and statistically significant, with livable area and exterior conditions being the most influential of the predictors. The coefficients for age and it's quadratic adjustment showed that older homes sold for less while the coefficients for the number of bedrooms showed that it became less statistically significant as non-structural predictors were introduced. \n\nAs census variables are introduced in Model 2, median income, educational attainment, and poverty rate all show expected relationships: higher income and education levels are associated with higher sale prices, while higher poverty rates are negatively associated.Our spatial features introduced in Model 3, distance from the nearest college and density of crime were also identified as statistically significant. In Model 4, the coefficient for wealthy neighborhood is large and positive. There is, however, a slight negative interaction between log(livable area) and wealthy neighborhoods. This suggests that while larger homes still tend to sell for more, the appreciation of value of each additional square foot is less pronounced in already expensive areas.\n\nOverall, the progression from Model 1 to Model 4 shows increasing explanatory power (R² rising from 0.35 to 0.60), and decreasing RMSE, indicating improved model fit as more structural and contextual variables are added.\n\n\n# Phase 5: Model Validation\n\nIn order to further assess the predictive power of our models, we performed 10-fold cross validation for each model in order to determine how well the model predicts for unseen data.\n\n**Code for 10-fold Cross-Validation**\n```{r 10 fold cross-validation results and scatterplots, echo=TRUE,results='hide'}\n\nparcel_data <- na.omit(parcel_data)\n\nctrl <- trainControl(\n  method = \"cv\",\n  number = 10  # intiate 10-fold CV\n)\n\nmodel_cv1 <-  train(log_sale_price ~ \n                      number_of_bathrooms +\n                      number_of_bedrooms +\n                      log_livable_area +\n                      garage_spaces + \n                      Age + I(Age^2) + \n                      exterior_good,\n                     data = parcel_data,\n                       method = \"lm\",\n                       trControl = ctrl)\n\n  \nmodel_cv2 <- train(log_sale_price ~ \n                     number_of_bathrooms +\n                     number_of_bedrooms + \n                     log_livable_area  +\n                     garage_spaces +\n                     Age + I(Age^2) + \n                     exterior_good + \n                     median_incomeE + \n                     percentage_bach + \n                     percentage_pov,\n                     data = parcel_data,\n                      method = \"lm\",\n                      trControl = ctrl\n)\n\n\nmodel_cv3 <- train(log_sale_price ~ \n                     number_of_bathrooms +\n                     garage_spaces +\n                     Age + I(Age^2) + \n                     exterior_good + \n                     log_livable_area +\n                     median_incomeE + \n                     percentage_bach +\n                     percentage_pov + \n                     college_nn1 + \n                     violent_crime_600ft,\n                     data = parcel_data,\n                    method = \"lm\",\n                    trControl = ctrl\n)\n\n\n\nmodel_cv4 <- train(log_sale_price ~ \n                     number_of_bathrooms+\n                     garage_spaces + \n                     Age + I(Age^2) +\n                     exterior_good + \n                     log_livable_area * wealthy_neighborhood + \n                     median_incomeE +\n                     percentage_bach + \n                     percentage_pov +\n                     college_nn1 + \n                     violent_crime_600ft,\n                     data = parcel_data,\n                      method = \"lm\",\n                    trControl = ctrl\n)\n\n```\n\n\nBased on each model's measurement average squared prediction error (RMSE),  average absolute difference between predicted and actual values (MAE), and  reported proportion of explained variance (R^2), we determined that Model 4's inclusion of structural, socioeconomic, spatial, and interactive effects all contributed to smaller errors between predicted values and actual values and offered greater explanatory power. \n\n\n```{r cross-validation summary table, echo=FALSE}\n\nresults_table <- rbind(\n  cbind(Model = \"Model 1\", model_cv1$results),\n  cbind(Model = \"Model 2\", model_cv2$results),\n  cbind(Model = \"Model 3\", model_cv3$results),\n  cbind(Model = \"Model 4\", model_cv4$results)\n)\n\nresults_table %>%\n  select(Model, RMSE, Rsquared, MAE) %>%\n  mutate(across(where(is.numeric), round, 4)) %>%\n  kable(caption = \"Table 6. Cross-Validated Performance Metrics for Four Models\")\n\n```\n\n\n\n```{r predicted vs actual plot, echo=FALSE}\n\nmodel_data_used <- model.frame(model4)\n\nmodel_data_used$Predicted <- model4$fitted.values\n\nggplot(model_data_used, aes(x = log_sale_price, y = Predicted)) +\n  geom_point(alpha = 0.4, color = \"steelblue\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Figure 6. Predicted vs Actual (Model 4)\",\n    x = \"Actual log(sale_price)\",\n    y = \"Predicted log(sale_price)\"\n  ) +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n\n```\n\nThe graph of the actual logged sale prices by the predicted logged sale prices compliments our model performance metrics found in Table 6 as points cluster closely around the reference line suggesting stable consistency in errors and moderate ability to predict sale prices.\n\n\n# Phase 6: Model Diagnostics\n\nWhen using linear regression to model relationships, we assume a number of conditions are met to support the validity of using a linear model. Here we test various linear modeling assumptions to determine the appropriateness of our model.\n\nOne linear model assumption is the assumption that the relationship is actually linear. \nIf the linearity assumption is met, residuals should be randomly scattered around the zero line with no discernible pattern.\n\nIn Figure 7, we plotted the residuals or prediction errors by the model's fitted values. The red dashed line at zero marks where residuals would fall if predictions were perfect.\nIn this plot, the residuals appear to fan out as fitted values increase, suggesting a possible violation of the linearity. This pattern may indicate that the model under- or over-predicts at different price levels.\n\n```{r residual plot, echo=FALSE}\n\nres_df <- data.frame(\n  Fitted = fitted(model4),\n  Residuals = residuals(model4)\n)\n\n# Plot using ggplot\nggplot(res_df, aes(x = Fitted, y = Residuals)) +\n  geom_point(alpha = 0.6, color=\"steelblue\") +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Figure 7. Residual Plot\", x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n  \n```\n\nAnother assumption we test is the normal distribution of residuals or errors.  In Figure 8, we test the assumption of normally distributed residuals using a Q-Q plot. If normality of residual's is met, the sample quantile points should fall roughly along the blue reference line representing theoretical quantiles of normal distribution.\n\nIn this plot, the residuals deviate from the line, particularly in the tails at low and high values, indicating non-normality. \n\n```{r q-q plot, echo=FALSE}\n\nggplot(res_df, aes(sample = Residuals)) +\n  stat_qq() +\n  stat_qq_line(color = \"steelblue\") +\n  labs(title = \"Figure 8. Q-Q Plot of Residuals\",\n       x = \"Theoretical Quantiles\",\n       y = \"Sample Quantiles\") +\n  theme_minimal()+\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\"\n  )\n\n```\n\nOne last regression assumption check we performed was determining whether there were influential outliers present. Figure 9 displays Cook’s Distance values for each observation, with colors indicating whether the point is flagged as influential, blue being none influential observations and red being the influential obeservations. A substantial large number of our observations were marked as influential, suggesting that many data points have both high leverage and large residuals.  \n\n```{r cooks distance, echo=FALSE}\n\nmodel4_data <- model.frame(model4)\n\n# Add diagnostics to model_data\nmodel4_data <- model4_data %>%\n  mutate(\n    cooks_d = cooks.distance(model4),\n    leverage = hatvalues(model4),\n    is_influential = cooks_d > 4 / nrow(model4_data)\n  )\n\n# Plot Cook's Distance\nggplot(model4_data, aes(x = 1:nrow(model4_data), y = cooks_d)) +\n  geom_point(aes(color = is_influential), size = 2) +\n  geom_hline(yintercept = 4 / nrow(model4_data), \n             linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = c(\"steelblue\", \"red\")) +\n  labs(title = \"Figure 9. Cook's Distance\",\n       x = \"Observation\", y = \"Cook's D\") +\n  theme_minimal() +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0.5),\n    plot.title.position = \"plot\")\n  \n```\n\n# Phase 7: Conclusions & Recommendations\n\nThe final model demonstrates strong performance, achieving an adjusted R² of 0.591 and explaining nearly 59% of the variation in housing prices across Philadelphia. This marks a substantial improvement over the baseline structural model (Model 1, R² = 0.35), highlighting the value of incorporating  spatial characteristics alongside structural and socioeconomic factors. \n\nAmong all predictors, total livable area emerges as the most influential driver of price, followed by the number of bathrooms and garage spaces. Exterior condition, median income, and educational attainment also show positive associations. Conversely, poverty rate and local crime density are negatively associated with price. \n\nThe interaction between living area and wealthy neighborhoods reveal that additional square footage may not have as much of an impact on price in high-value areas. Spatial dependencies are also evident in the model’s predictive accuracy as prediction errors show spatial patterns. The model performs best in mid-range price neighborhoods but struggles in areas like Nicetown, Fairhill, and Upper Kensington, where residual errors are higher. These disparities raise important equity concerns in the context of policy as these areas that are predisposed to under-prediction in modeling are also historical disadvantaged neighborhoods.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"Rutherford_Angel_Appendix.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":"cosmo","title":"Philadelphia Housing Model - Technical Appendix","author":"Angel Rutherford","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}